{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为啥训练到一定次数，ratio会变成nan？\n",
    "# 为什么pi_prob(a)是(32,1)\n",
    "# 而我的pi_prob(a)却是(32,32)\n",
    "# 我没有理解源码在建立actor网络的时候是怎么建立的，因为不需要构造模型，所以它出来pi不是32个state对应一个策略\n",
    "\n",
    "# 我知道问题出在哪了，因为之前的tfp和tensorflow是一体的，可以构造输出就是tfp的分布的模型\n",
    "# 而现在分开了，tfp的分布不属于一个op，所以没有办法放到模型里\n",
    "\n",
    "# 为什么mu，sigma我们俩的程序都是(32,1),但是莫凡的只输出了1个pi，我却输出了32个。\n",
    "# 也就是说，莫凡是输入了32个s，产生了32个mu，32个sigma，但是只产生了1个pi\n",
    "# 而我产生了32个mu，32个sigma，但是产生了32个pi，正因为如此，之后给了32个a，每个pi都产生了prob，所以prob形状是(32,32)，ratio自然也是(32,32),但是ratio要乘(32,1)的adv，所以出错了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_MAX = 300\n",
    "EP_LEN = 300\n",
    "GAMMA = 0.9\n",
    "A_LR = 0.0001\n",
    "C_LR = 0.0002\n",
    "BATCH = 32\n",
    "A_UPDATE_STEPS = 10\n",
    "C_UPDATE_STEPS = 10\n",
    "S_DIM, A_DIM = 3, 1   #举杆子的游戏就是这么个维度\n",
    "METHOD = [\n",
    "    dict(name='kl_pen', kl_target=0.01, lam=0.5),  #更新时候控制old和new参数近似的第一种方法KL\n",
    "    dict(name='clip', epsilon=0.2)                 #更新时的第二种方法CLIP\n",
    "][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'kl_pen', 'kl_target': 0.01, 'lam': 0.5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO():\n",
    "    def __init__(self):\n",
    "        self.build_actor()  #创建actor,只创建一个actor，用的时候先后顺序用\n",
    "        self.build_critic() #创建critic\n",
    "\n",
    "    \n",
    "    def build_actor(self):\n",
    "        '''建立网络的结构，actor'''\n",
    "        # actor_new---------------------------------------------\n",
    "        s = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1 = tf.keras.layers.Dense(100, activation='relu',name='l1')(s)\n",
    "        mu = tf.keras.layers.Dense(A_DIM, activation='tanh',name='mu')(l1)\n",
    "        sigma = tf.keras.layers.Dense(A_DIM, activation='softplus',name='sigma')(l1)\n",
    "        \n",
    "        self.actor_new = tf.keras.Model(inputs=s, outputs=[mu,sigma])\n",
    "        self.a_optimizer = tf.keras.optimizers.Adam(A_LR)\n",
    "        \n",
    "        # actor_old-------------------------------------------------\n",
    "        s_1 = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1_1 = tf.keras.layers.Dense(100, activation='relu',name='l1')(s_1)\n",
    "        mu_1 = tf.keras.layers.Dense(A_DIM, activation='tanh',name='mu')(l1_1)\n",
    "        sigma_1 = tf.keras.layers.Dense(A_DIM, activation='softplus',name='sigma')(l1_1)\n",
    "        \n",
    "        self.actor_old = tf.keras.Model(inputs=s_1, outputs=[mu_1,sigma_1])\n",
    "    \n",
    "    def build_critic(self): \n",
    "        '''建立网络的结构，critic'''\n",
    "        # critic\n",
    "        s_c = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1_c = tf.keras.layers.Dense(100, activation='relu')(s_c)\n",
    "        v = tf.keras.layers.Dense(1)(l1_c)\n",
    "        \n",
    "        self.critic = tf.keras.Model(inputs=s_c, outputs=v)\n",
    "        self.c_optimizer = tf.keras.optimizers.Adam(C_LR)\n",
    "        \n",
    "    def update_new_old_actor(self):\n",
    "        '''更新老actor参数'''\n",
    "        #使用set_weights和get_weights的方法对每层的权重进行复制转移\n",
    "        #--------------------actor的两个网络的迁移--------------------------------\n",
    "        self.actor_old.set_weights(self.actor_new.get_weights())\n",
    "        \n",
    "    def learn(self, s, a, r):\n",
    "        '''学习，输入的是batch的s，会产生batch个normdist，对于batch的a，会产生batch*batch的proba'''      \n",
    "        # 旧网络产生的策略,不需要训练\n",
    "        [mu1, sigma1] = self.actor_old(s, training=False)\n",
    "        mu1 *= 2 #为了使-1,1到-2,2内部\n",
    "        \n",
    "        #不要squeeze，直接生成dis\n",
    "        pi_old = tfp.distributions.Normal(mu1, sigma1)  # pi_old是old网络的策略,一共有1个形状为[32,1]\n",
    "        \n",
    "        #每次学习更新一下新旧网络，\n",
    "        self.update_new_old_actor()\n",
    "        \n",
    "        #训练\n",
    "        with tf.GradientTape(persistent=True) as a_tap, tf.GradientTape(persistent=True) as c_tap:\n",
    "            # 新网络产生的策略\n",
    "            # 注意，网络产生的值一定要放在Gradient下面，不然没有梯度\n",
    "            [mu, sigma] = self.actor_new(s)\n",
    "            mu *= 2\n",
    "            \n",
    "            #不要squeeze\n",
    "            pi = tfp.distributions.Normal(mu, sigma)  # pi是现在的策略，[32,1]\n",
    "                    \n",
    "            #计算loss\n",
    "            v = self.critic(s) #计算s的价值\n",
    "            adv = r - v        #计算增益,形状是(32,1)\n",
    "\n",
    "            \n",
    "#             ratio = tf.exp(pi.log_prob(a) - pi_old.log_prob(a))\n",
    "            ratio = pi.prob(a) / pi_old.prob(a)    #ratio的shape应该是(32,1)!!!!!  ,这回肯定是了！\n",
    "#             print('ratio',ratio.shape)\n",
    "            \n",
    "            surr = ratio * adv\n",
    "            \n",
    "            # a的loss计算-------------------------------------------------------------------------------------------------\n",
    "            # a_loss的算法因为两种方法而不同\n",
    "            if METHOD['name'] == 'kl_pen':   # kl方法\n",
    "                lamda = METHOD['lam']\n",
    "                kl = tfp.distributions.kl_divergence(pi_old, pi)  #计算两个策略之间的KL散度\n",
    "                kl_mean = tf.reduce_mean(kl)\n",
    "                a_loss = -(tf.reduce_mean(surr - lamda * kl))\n",
    "                \n",
    "            else:                            # clip方法\n",
    "                a_loss = - tf.reduce_mean(tf.minimum(\n",
    "                    surr,\n",
    "                    tf.clip_by_value(ratio, 1.-METHOD['epsilon'], 1.+METHOD['epsilon'])*adv))\n",
    "                \n",
    "                \n",
    "            # c的loss计算--------------------------------------------------------------------------------------------------\n",
    "            c_loss = tf.reduce_mean(tf.square(adv))\n",
    "                    \n",
    "        # 更新actor----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        if METHOD['name'] == 'kl_pen':    #kl方法对应着kl的更新方式\n",
    "            for _ in range(A_UPDATE_STEPS): #给actor更新10次 ,grads在一个循环里面只能调用一次，所以，不能这么写，除非加上persistent\n",
    "                grads_a = a_tap.gradient(a_loss, self.actor_new.trainable_variables)\n",
    "                self.a_optimizer.apply_gradients(zip(grads_a, self.actor_new.trainable_variables))\n",
    "                # 设置内部终止条件\n",
    "                kl_now = kl_mean\n",
    "                if kl_now >4 * METHOD['kl_target']:\n",
    "                    break\n",
    "            if kl_now < METHOD['kl_target']/1.5:\n",
    "                METHOD['lam'] /= 2\n",
    "            elif kl_now > METHOD['kl_target']*1.5:\n",
    "                METHOD['lam'] *= 2\n",
    "            METHOD['lam'] = np.clip(METHOD['lam'], 1e-4, 10)\n",
    "        \n",
    "        else:                            #clip方法对应clip更新方式\n",
    "            for _ in range(A_UPDATE_STEPS): # 就是简单地用clip方式计算的loss给a更新10次\n",
    "                grads_a = a_tap.gradient(a_loss, self.actor_new.trainable_variables)\n",
    "                self.a_optimizer.apply_gradients(zip(grads_a, self.actor_new.trainable_variables))\n",
    "                \n",
    "        # 更新critic------------------------------------------------------------------------------------------------------------\n",
    "        for _ in range(C_UPDATE_STEPS):\n",
    "            grads_c = c_tap.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(grads_c, self.critic.trainable_variables)) \n",
    "        \n",
    "    def choose_action(self, s):\n",
    "        '''choose_action的时候就进来了一个s，所以只会产生一个normdist，也只会sample出来一个a'''\n",
    "        s = np.expand_dims(s, axis=0)\n",
    "        [mu, sigma] = self.actor_new(s, training=False)\n",
    "#         mu = tf.squeeze(mu*2)\n",
    "#         sigma = tf.squeeze(sigma)\n",
    "        mu *= 2\n",
    "        # 不要squeeze，这回就对了，输出形状是[1,1]只取第一维，得到[xx],对应着step！\n",
    "        #创建一个正态分布\n",
    "        normal_dist = tfp.distributions.Normal(mu, sigma)\n",
    "        act_choosed = tf.clip_by_value(normal_dist.sample(1)[0][0], -2,2)  \n",
    "        act_choosed = act_choosed.numpy()\n",
    "        return act_choosed\n",
    "    \n",
    "    def get_v(self, s):\n",
    "        if s.ndim < 2:\n",
    "            s = np.expand_dims(s, axis=0)\n",
    "        v = self.critic(s)\n",
    "        return v[0][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "all_ep_r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 0 |ep_r: -2787 |Lam: 0.0020\n",
      "EP: 1 |ep_r: -2745 |Lam: 0.0001\n",
      "EP: 2 |ep_r: -2736 |Lam: 0.0001\n",
      "EP: 3 |ep_r: -2752 |Lam: 0.0001\n",
      "EP: 4 |ep_r: -2636 |Lam: 0.0001\n",
      "EP: 5 |ep_r: -2492 |Lam: 0.0001\n",
      "EP: 6 |ep_r: -2502 |Lam: 0.0001\n",
      "EP: 7 |ep_r: -2327 |Lam: 0.0001\n",
      "EP: 8 |ep_r: -2318 |Lam: 0.0001\n",
      "EP: 9 |ep_r: -2232 |Lam: 0.0001\n",
      "EP: 10 |ep_r: -2349 |Lam: 0.0001\n",
      "EP: 11 |ep_r: -1492 |Lam: 0.0002\n",
      "EP: 12 |ep_r: -1840 |Lam: 0.0001\n",
      "EP: 13 |ep_r: -2239 |Lam: 0.0001\n",
      "EP: 14 |ep_r: -2114 |Lam: 0.0001\n",
      "EP: 15 |ep_r: -2021 |Lam: 0.0001\n",
      "EP: 16 |ep_r: -1979 |Lam: 0.0001\n",
      "EP: 17 |ep_r: -2152 |Lam: 0.0001\n",
      "EP: 18 |ep_r: -1966 |Lam: 0.0001\n",
      "EP: 19 |ep_r: -2280 |Lam: 0.0001\n",
      "EP: 20 |ep_r: -2228 |Lam: 0.0001\n",
      "EP: 21 |ep_r: -2158 |Lam: 0.0001\n",
      "EP: 22 |ep_r: -2229 |Lam: 0.0001\n",
      "EP: 23 |ep_r: -2018 |Lam: 0.0001\n",
      "EP: 24 |ep_r: -1825 |Lam: 0.0001\n",
      "EP: 25 |ep_r: -1982 |Lam: 0.0001\n",
      "EP: 26 |ep_r: -1854 |Lam: 0.0001\n",
      "EP: 27 |ep_r: -2290 |Lam: 0.0001\n",
      "EP: 28 |ep_r: -1854 |Lam: 0.0001\n",
      "EP: 29 |ep_r: -1943 |Lam: 0.0001\n",
      "EP: 30 |ep_r: -1773 |Lam: 0.0001\n",
      "EP: 31 |ep_r: -2219 |Lam: 0.0001\n",
      "EP: 32 |ep_r: -2122 |Lam: 0.0001\n",
      "EP: 33 |ep_r: -1486 |Lam: 0.0001\n",
      "EP: 34 |ep_r: -2082 |Lam: 0.0001\n",
      "EP: 35 |ep_r: -1944 |Lam: 0.0001\n",
      "EP: 36 |ep_r: -2081 |Lam: 0.0001\n",
      "EP: 37 |ep_r: -1750 |Lam: 0.0001\n",
      "EP: 38 |ep_r: -1872 |Lam: 0.0001\n",
      "EP: 39 |ep_r: -1894 |Lam: 0.0001\n",
      "EP: 40 |ep_r: -2469 |Lam: 0.0001\n",
      "EP: 41 |ep_r: -1697 |Lam: 0.0001\n",
      "EP: 42 |ep_r: -2391 |Lam: 0.0001\n",
      "EP: 43 |ep_r: -1938 |Lam: 0.0001\n",
      "EP: 44 |ep_r: -2286 |Lam: 0.0001\n",
      "EP: 45 |ep_r: -1777 |Lam: 0.0001\n",
      "EP: 46 |ep_r: -1973 |Lam: 0.0001\n",
      "EP: 47 |ep_r: -1913 |Lam: 0.0001\n",
      "EP: 48 |ep_r: -1998 |Lam: 0.0001\n",
      "EP: 49 |ep_r: -2255 |Lam: 0.0001\n",
      "EP: 50 |ep_r: -1812 |Lam: 0.0001\n",
      "EP: 51 |ep_r: -1774 |Lam: 0.0001\n",
      "EP: 52 |ep_r: -1969 |Lam: 0.0001\n",
      "EP: 53 |ep_r: -1862 |Lam: 0.0001\n",
      "EP: 54 |ep_r: -2273 |Lam: 0.0001\n",
      "EP: 55 |ep_r: -2219 |Lam: 0.0001\n",
      "EP: 56 |ep_r: -2124 |Lam: 0.0001\n",
      "EP: 57 |ep_r: -2380 |Lam: 0.0001\n",
      "EP: 58 |ep_r: -1719 |Lam: 0.0001\n",
      "EP: 59 |ep_r: -1955 |Lam: 0.0001\n",
      "EP: 60 |ep_r: -1695 |Lam: 0.0001\n",
      "EP: 61 |ep_r: -1829 |Lam: 0.0001\n",
      "EP: 62 |ep_r: -2137 |Lam: 0.0001\n",
      "EP: 63 |ep_r: -1837 |Lam: 0.0001\n",
      "EP: 64 |ep_r: -2401 |Lam: 0.0001\n",
      "EP: 65 |ep_r: -2171 |Lam: 0.0001\n",
      "EP: 66 |ep_r: -2098 |Lam: 0.0001\n",
      "EP: 67 |ep_r: -1850 |Lam: 0.0001\n",
      "EP: 68 |ep_r: -1720 |Lam: 0.0001\n",
      "EP: 69 |ep_r: -1832 |Lam: 0.0001\n",
      "EP: 70 |ep_r: -1939 |Lam: 0.0001\n",
      "EP: 71 |ep_r: -1580 |Lam: 0.0001\n",
      "EP: 72 |ep_r: -1863 |Lam: 0.0001\n",
      "EP: 73 |ep_r: -1965 |Lam: 0.0001\n",
      "EP: 74 |ep_r: -1585 |Lam: 0.0001\n",
      "EP: 75 |ep_r: -2185 |Lam: 0.0001\n",
      "EP: 76 |ep_r: -1809 |Lam: 0.0001\n",
      "EP: 77 |ep_r: -1915 |Lam: 0.0001\n",
      "EP: 78 |ep_r: -2319 |Lam: 0.0001\n",
      "EP: 79 |ep_r: -1703 |Lam: 0.0001\n",
      "EP: 80 |ep_r: -1571 |Lam: 0.0001\n",
      "EP: 81 |ep_r: -2034 |Lam: 0.0001\n",
      "EP: 82 |ep_r: -1668 |Lam: 0.0001\n",
      "EP: 83 |ep_r: -1853 |Lam: 0.0001\n",
      "EP: 84 |ep_r: -1889 |Lam: 0.0001\n",
      "EP: 85 |ep_r: -1738 |Lam: 0.0001\n",
      "EP: 86 |ep_r: -1709 |Lam: 0.0001\n",
      "EP: 87 |ep_r: -1707 |Lam: 0.0001\n",
      "EP: 88 |ep_r: -1505 |Lam: 0.0001\n",
      "EP: 89 |ep_r: -1855 |Lam: 0.0001\n",
      "EP: 90 |ep_r: -1738 |Lam: 0.0001\n",
      "EP: 91 |ep_r: -1479 |Lam: 0.0001\n",
      "EP: 92 |ep_r: -1898 |Lam: 0.0001\n",
      "EP: 93 |ep_r: -1593 |Lam: 0.0001\n",
      "EP: 94 |ep_r: -1782 |Lam: 0.0001\n",
      "EP: 95 |ep_r: -1400 |Lam: 0.0001\n",
      "EP: 96 |ep_r: -1598 |Lam: 0.0001\n",
      "EP: 97 |ep_r: -1727 |Lam: 0.0001\n",
      "EP: 98 |ep_r: -1699 |Lam: 0.0001\n",
      "EP: 99 |ep_r: -1755 |Lam: 0.0001\n",
      "EP: 100 |ep_r: -2143 |Lam: 0.0001\n",
      "EP: 101 |ep_r: -1453 |Lam: 0.0001\n",
      "EP: 102 |ep_r: -1856 |Lam: 0.0001\n",
      "EP: 103 |ep_r: -1746 |Lam: 0.0001\n",
      "EP: 104 |ep_r: -2129 |Lam: 0.0001\n",
      "EP: 105 |ep_r: -1625 |Lam: 0.0001\n",
      "EP: 106 |ep_r: -1625 |Lam: 0.0001\n",
      "EP: 107 |ep_r: -1366 |Lam: 0.0001\n",
      "EP: 108 |ep_r: -1382 |Lam: 0.0001\n",
      "EP: 109 |ep_r: -1458 |Lam: 0.0001\n",
      "EP: 110 |ep_r: -2128 |Lam: 0.0001\n",
      "EP: 111 |ep_r: -2357 |Lam: 0.0001\n",
      "EP: 112 |ep_r: -1621 |Lam: 0.0001\n",
      "EP: 113 |ep_r: -1860 |Lam: 0.0001\n",
      "EP: 114 |ep_r: -1875 |Lam: 0.0001\n",
      "EP: 115 |ep_r: -1635 |Lam: 0.0001\n",
      "EP: 116 |ep_r: -1741 |Lam: 0.0001\n",
      "EP: 117 |ep_r: -1794 |Lam: 0.0001\n",
      "EP: 118 |ep_r: -1633 |Lam: 0.0001\n",
      "EP: 119 |ep_r: -1602 |Lam: 0.0001\n",
      "EP: 120 |ep_r: -1401 |Lam: 0.0001\n",
      "EP: 121 |ep_r: -1663 |Lam: 0.0001\n",
      "EP: 122 |ep_r: -2144 |Lam: 0.0001\n",
      "EP: 123 |ep_r: -1399 |Lam: 0.0002\n",
      "EP: 124 |ep_r: -1592 |Lam: 0.0002\n",
      "EP: 125 |ep_r: -1615 |Lam: 0.0001\n",
      "EP: 126 |ep_r: -2300 |Lam: 0.0001\n",
      "EP: 127 |ep_r: -1908 |Lam: 0.0001\n",
      "EP: 128 |ep_r: -1851 |Lam: 0.0001\n",
      "EP: 129 |ep_r: -1700 |Lam: 0.0001\n",
      "EP: 130 |ep_r: -1813 |Lam: 0.0001\n",
      "EP: 131 |ep_r: -1528 |Lam: 0.0001\n",
      "EP: 132 |ep_r: -1558 |Lam: 0.0001\n",
      "EP: 133 |ep_r: -1412 |Lam: 0.0001\n",
      "EP: 134 |ep_r: -2332 |Lam: 0.0001\n",
      "EP: 135 |ep_r: -1956 |Lam: 0.0001\n",
      "EP: 136 |ep_r: -1505 |Lam: 0.0001\n",
      "EP: 137 |ep_r: -2325 |Lam: 0.0001\n",
      "EP: 138 |ep_r: -1082 |Lam: 0.0001\n",
      "EP: 139 |ep_r: -2143 |Lam: 0.0001\n",
      "EP: 140 |ep_r: -1398 |Lam: 0.0001\n",
      "EP: 141 |ep_r: -1013 |Lam: 0.0001\n",
      "EP: 142 |ep_r: -1701 |Lam: 0.0001\n",
      "EP: 143 |ep_r: -2345 |Lam: 0.0001\n",
      "EP: 144 |ep_r: -1696 |Lam: 0.0001\n",
      "EP: 145 |ep_r: -1560 |Lam: 0.0004\n",
      "EP: 146 |ep_r: -1533 |Lam: 0.0001\n",
      "EP: 147 |ep_r: -1695 |Lam: 0.0001\n",
      "EP: 148 |ep_r: -1711 |Lam: 0.0001\n",
      "EP: 149 |ep_r: -1176 |Lam: 0.0001\n",
      "EP: 150 |ep_r: -1500 |Lam: 0.0001\n",
      "EP: 151 |ep_r: -1552 |Lam: 0.0001\n",
      "EP: 152 |ep_r: -1886 |Lam: 0.0001\n",
      "EP: 153 |ep_r: -1427 |Lam: 0.0001\n",
      "EP: 154 |ep_r: -1452 |Lam: 0.0001\n",
      "EP: 155 |ep_r: -1750 |Lam: 0.0001\n",
      "EP: 156 |ep_r: -1035 |Lam: 0.0001\n",
      "EP: 157 |ep_r: -1864 |Lam: 0.0001\n",
      "EP: 158 |ep_r: -1810 |Lam: 0.0001\n",
      "EP: 159 |ep_r: -1443 |Lam: 0.0001\n",
      "EP: 160 |ep_r: -2278 |Lam: 0.0001\n",
      "EP: 161 |ep_r: -1152 |Lam: 0.0001\n",
      "EP: 162 |ep_r: -1301 |Lam: 0.0001\n",
      "EP: 163 |ep_r: -1544 |Lam: 0.0001\n",
      "EP: 164 |ep_r: -1022 |Lam: 0.0001\n",
      "EP: 165 |ep_r: -2315 |Lam: 0.0001\n",
      "EP: 166 |ep_r: -1541 |Lam: 0.0001\n",
      "EP: 167 |ep_r: -1555 |Lam: 0.0001\n",
      "EP: 168 |ep_r: -1453 |Lam: 0.0001\n",
      "EP: 169 |ep_r: -2025 |Lam: 0.0002\n",
      "EP: 170 |ep_r: -1435 |Lam: 0.0001\n",
      "EP: 171 |ep_r: -1035 |Lam: 0.0002\n",
      "EP: 172 |ep_r: -1882 |Lam: 0.0256\n",
      "EP: 173 |ep_r: -2205 |Lam: 10.0000\n",
      "EP: 174 |ep_r: -1872 |Lam: 0.0781\n",
      "EP: 175 |ep_r: -2331 |Lam: 0.0001\n",
      "EP: 176 |ep_r: -2024 |Lam: 0.0001\n",
      "EP: 177 |ep_r: -2175 |Lam: 0.0001\n",
      "EP: 178 |ep_r: -2114 |Lam: 0.0001\n",
      "EP: 179 |ep_r: -2304 |Lam: 0.0001\n",
      "EP: 180 |ep_r: -2134 |Lam: 0.0001\n",
      "EP: 181 |ep_r: -2340 |Lam: 0.0001\n",
      "EP: 182 |ep_r: -2193 |Lam: 0.0001\n",
      "EP: 183 |ep_r: -2152 |Lam: 0.0001\n",
      "EP: 184 |ep_r: -2079 |Lam: 0.0001\n",
      "EP: 185 |ep_r: -2055 |Lam: 0.0001\n",
      "EP: 186 |ep_r: -2227 |Lam: 0.0001\n",
      "EP: 187 |ep_r: -2333 |Lam: 0.0001\n",
      "EP: 188 |ep_r: -1905 |Lam: 0.0001\n",
      "EP: 189 |ep_r: -2044 |Lam: 0.0001\n",
      "EP: 190 |ep_r: -1913 |Lam: 0.0001\n",
      "EP: 191 |ep_r: -2007 |Lam: 0.0001\n",
      "EP: 192 |ep_r: -2177 |Lam: 0.0001\n",
      "EP: 193 |ep_r: -2274 |Lam: 0.0001\n",
      "EP: 194 |ep_r: -2066 |Lam: 0.0001\n",
      "EP: 195 |ep_r: -2274 |Lam: 0.0001\n",
      "EP: 196 |ep_r: -2188 |Lam: 0.0001\n",
      "EP: 197 |ep_r: -1862 |Lam: 0.0001\n",
      "EP: 198 |ep_r: -2072 |Lam: 0.0001\n",
      "EP: 199 |ep_r: -2320 |Lam: 0.0001\n",
      "EP: 200 |ep_r: -1987 |Lam: 0.0001\n",
      "EP: 201 |ep_r: -1907 |Lam: 0.0001\n",
      "EP: 202 |ep_r: -2329 |Lam: 0.0001\n",
      "EP: 203 |ep_r: -2210 |Lam: 0.0001\n",
      "EP: 204 |ep_r: -2323 |Lam: 0.0001\n",
      "EP: 205 |ep_r: -2080 |Lam: 0.0001\n",
      "EP: 206 |ep_r: -2275 |Lam: 0.0001\n",
      "EP: 207 |ep_r: -2274 |Lam: 0.0001\n",
      "EP: 208 |ep_r: -1978 |Lam: 0.0001\n",
      "EP: 209 |ep_r: -2233 |Lam: 0.0001\n",
      "EP: 210 |ep_r: -2158 |Lam: 0.0001\n",
      "EP: 211 |ep_r: -2184 |Lam: 0.0001\n",
      "EP: 212 |ep_r: -2171 |Lam: 0.0001\n",
      "EP: 213 |ep_r: -2208 |Lam: 0.0001\n",
      "EP: 214 |ep_r: -1976 |Lam: 0.0001\n",
      "EP: 215 |ep_r: -1631 |Lam: 0.0004\n",
      "EP: 216 |ep_r: -2035 |Lam: 0.0001\n",
      "EP: 217 |ep_r: -1883 |Lam: 0.0001\n",
      "EP: 218 |ep_r: -1884 |Lam: 0.0001\n",
      "EP: 219 |ep_r: -2041 |Lam: 0.0001\n",
      "EP: 220 |ep_r: -2050 |Lam: 0.0001\n",
      "EP: 221 |ep_r: -1503 |Lam: 0.0001\n",
      "EP: 222 |ep_r: -1927 |Lam: 0.0001\n",
      "EP: 223 |ep_r: -2056 |Lam: 0.0001\n",
      "EP: 224 |ep_r: -1925 |Lam: 0.0004\n",
      "EP: 225 |ep_r: -1864 |Lam: 0.0008\n",
      "EP: 226 |ep_r: -1684 |Lam: 0.0001\n",
      "EP: 227 |ep_r: -1855 |Lam: 0.0001\n",
      "EP: 228 |ep_r: -1154 |Lam: 0.0001\n",
      "EP: 229 |ep_r: -1743 |Lam: 0.0002\n",
      "EP: 230 |ep_r: -1759 |Lam: 0.0001\n",
      "EP: 231 |ep_r: -779 |Lam: 0.0001\n",
      "EP: 232 |ep_r: -1564 |Lam: 0.0001\n",
      "EP: 233 |ep_r: -1846 |Lam: 0.0001\n",
      "EP: 234 |ep_r: -1426 |Lam: 0.0001\n",
      "EP: 235 |ep_r: -1743 |Lam: 0.0001\n",
      "EP: 236 |ep_r: -712 |Lam: 0.0001\n",
      "EP: 237 |ep_r: -958 |Lam: 0.0001\n",
      "EP: 238 |ep_r: -1204 |Lam: 0.0001\n",
      "EP: 239 |ep_r: -2016 |Lam: 0.0001\n",
      "EP: 240 |ep_r: -779 |Lam: 0.0001\n",
      "EP: 241 |ep_r: -2047 |Lam: 0.0001\n",
      "EP: 242 |ep_r: -2312 |Lam: 0.0001\n",
      "EP: 243 |ep_r: -1269 |Lam: 0.0001\n",
      "EP: 244 |ep_r: -937 |Lam: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 245 |ep_r: -1053 |Lam: 0.0001\n",
      "EP: 246 |ep_r: -923 |Lam: 0.0001\n",
      "EP: 247 |ep_r: -647 |Lam: 0.0001\n",
      "EP: 248 |ep_r: -645 |Lam: 0.0001\n",
      "EP: 249 |ep_r: -856 |Lam: 0.0001\n",
      "EP: 250 |ep_r: -649 |Lam: 0.0001\n",
      "EP: 251 |ep_r: -894 |Lam: 0.0001\n",
      "EP: 252 |ep_r: -2019 |Lam: 0.0001\n",
      "EP: 253 |ep_r: -1748 |Lam: 0.0001\n",
      "EP: 254 |ep_r: -916 |Lam: 0.0001\n",
      "EP: 255 |ep_r: -648 |Lam: 0.0001\n",
      "EP: 256 |ep_r: -2317 |Lam: 0.0001\n",
      "EP: 257 |ep_r: -900 |Lam: 0.0001\n",
      "EP: 258 |ep_r: -651 |Lam: 0.0001\n",
      "EP: 259 |ep_r: -1384 |Lam: 0.0001\n",
      "EP: 260 |ep_r: -1080 |Lam: 0.0008\n",
      "EP: 261 |ep_r: -790 |Lam: 0.0001\n",
      "EP: 262 |ep_r: -542 |Lam: 0.0001\n",
      "EP: 263 |ep_r: -717 |Lam: 0.0001\n",
      "EP: 264 |ep_r: -522 |Lam: 0.0001\n",
      "EP: 265 |ep_r: -1025 |Lam: 0.0001\n",
      "EP: 266 |ep_r: -1244 |Lam: 0.0001\n",
      "EP: 267 |ep_r: -1327 |Lam: 0.0001\n",
      "EP: 268 |ep_r: -513 |Lam: 0.0001\n",
      "EP: 269 |ep_r: -2319 |Lam: 0.0001\n",
      "EP: 270 |ep_r: -264 |Lam: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in range(EP_MAX):\n",
    "    s = env.reset()\n",
    "    buffer_s, buffer_a, buffer_r = [],[],[]\n",
    "    ep_r = 0\n",
    "    \n",
    "    for t in range(EP_LEN):\n",
    "        env.render()\n",
    "        a = ppo.choose_action(s)\n",
    "        s_, r, done, info = env.step(a)\n",
    "        buffer_s.append(s)\n",
    "        buffer_a.append(a)\n",
    "        buffer_r.append((r+8)/8)\n",
    "        s = s_\n",
    "        ep_r += r\n",
    "        \n",
    "        if (t+1)%BATCH==0 or t==EP_LEN-1:\n",
    "            v_s_ = ppo.get_v(s_)\n",
    "            discounted_r = []\n",
    "            for r in buffer_r[::-1]:\n",
    "                v_s_ = r + GAMMA * v_s_\n",
    "                discounted_r.append(v_s_)\n",
    "            discounted_r.reverse()\n",
    "            \n",
    "            bs, ba, br = np.vstack(buffer_s), np.vstack(buffer_a), np.expand_dims(np.array(discounted_r), axis=1)\n",
    "            \n",
    "            #清空三个buffer\n",
    "            buffer_s, buffer_a, buffer_r = [], [], []\n",
    "            \n",
    "            #学习\n",
    "            ppo.learn(bs, ba, br)\n",
    "            \n",
    "    # 用来显示奖励值\n",
    "    if ep == 0: all_ep_r.append(ep_r)\n",
    "    else: all_ep_r.append(all_ep_r[-1]*0.9 + ep_r*0.1)\n",
    "    \n",
    "    print('EP: %i'%ep,\n",
    "          '|ep_r: %i'%ep_r,\n",
    "          (\"|Lam: %.4f\" % METHOD['lam']) if METHOD['name'] == 'kl_pen' else '',\n",
    "          )\n",
    "    \n",
    "    if ep_r > -300:\n",
    "        break\n",
    "# 画图\n",
    "plt.plot(np.arange(len(all_ep_r)), all_ep_r)\n",
    "plt.xlabel('Episode');plt.ylabel('Moving averaged episode reward');plt.show()\n",
    "ppo.actor_new.save_weights('pp01_actor_weights.h5')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_test = PPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_test.actor_new.load_weights('pp01_actor_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5ba1fa0cd23d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEP_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppo_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0ms_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4edf6733b490>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m#创建一个正态分布\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mnormal_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mact_choosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mact_choosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact_choosed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mact_choosed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0msamples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mprepended\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m     \"\"\"\n\u001b[1;32m-> 1001\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_sample_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py\u001b[0m in \u001b[0;36m_call_sample_n\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m    977\u001b[0m           sample_shape, 'sample_shape')\n\u001b[0;32m    978\u001b[0m       samples = self._sample_n(\n\u001b[1;32m--> 979\u001b[1;33m           n, seed=seed() if callable(seed) else seed, **kwargs)\n\u001b[0m\u001b[0;32m    980\u001b[0m       \u001b[0mbatch_event_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       \u001b[0mfinal_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_event_shape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_probability\\python\\distributions\\normal.py\u001b[0m in \u001b[0;36m_sample_n\u001b[1;34m(self, n, seed)\u001b[0m\n\u001b[0;32m    191\u001b[0m     sampled = samplers.normal(\n\u001b[0;32m    192\u001b[0m         shape=shape, mean=0., stddev=1., dtype=self.dtype, seed=seed)\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msampled\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    507\u001b[0m   \"\"\"\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6161\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m   6162\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6163\u001b[1;33m         x, y)\n\u001b[0m\u001b[0;32m   6164\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(EP_MAX):\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(EP_LEN):\n",
    "        env.render()\n",
    "        a = ppo_test.choose_action(s)\n",
    "        s_, r, done, info = env.step(a)\n",
    "        s = s_\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何提取出全部的权重并且对权重进行运算，再赋值\n",
    "# 也就是软更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=(1,))\n",
    "x = tf.keras.layers.Dense(5)(i)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=i, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.get_weights()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = [w1*0.1 for w1 in w]\n",
    "print(w_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w1+w2 for w1,w2 in zip(w,w_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在建立网络的时候直接产生pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distnorm = tfp.distributions.Normal(0,1)\n",
    "dsitnorm2 = tfp.distributions.Normal([0,1],[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32)\n",
      "tfp.distributions.Normal(\"Normal\", batch_shape=[], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dsitnorm2)\n",
    "print(distnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16165093]\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "buffer_s, buffer_a, buffer_r = [],[],[]\n",
    "a = ppo.choose_action(s)\n",
    "print(a)\n",
    "for t in range(8):\n",
    "    ep_r = 0\n",
    "    a = ppo.choose_action(s)\n",
    "    s_, r, done, info = env.step(a)\n",
    "    buffer_s.append(s)\n",
    "    buffer_a.append(a)\n",
    "    buffer_r.append((r+8)/8)\n",
    "    s = s_\n",
    "    ep_r += r\n",
    "bs, ba, br = np.vstack(buffer_s), np.vstack(buffer_a), np.vstack(buffer_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05042878,  0.99872766,  0.66738899],\n",
       "       [-0.01850657,  0.99982874,  1.37915609],\n",
       "       [-0.12991862,  0.99152466,  2.23558554],\n",
       "       [-0.2813611 ,  0.95960196,  3.09850634],\n",
       "       [-0.45734555,  0.88928907,  3.79591537],\n",
       "       [-0.6434293 ,  0.76550554,  4.47923348],\n",
       "       [-0.81341724,  0.58168066,  5.02066649],\n",
       "       [-0.9401022 ,  0.34089274,  5.4585398 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24852428],\n",
       "       [ 0.7103859 ],\n",
       "       [ 0.79518205],\n",
       "       [-0.14861628],\n",
       "       [ 0.10900874],\n",
       "       [-0.21797436],\n",
       "       [ 0.01075213],\n",
       "       [-0.09659199]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70549313],\n",
       "       [ 0.66042514],\n",
       "       [ 0.57573741],\n",
       "       [ 0.44939201],\n",
       "       [ 0.29672194],\n",
       "       [ 0.1052202 ],\n",
       "       [-0.10939231],\n",
       "       [-0.34806021]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.05236873]\n",
      " [ 0.02980565]\n",
      " [ 0.00520472]\n",
      " [-0.03456562]\n",
      " [-0.05436929]\n",
      " [-0.06107465]\n",
      " [-0.06565797]\n",
      " [-0.079589  ]], shape=(8, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.5669595 ]\n",
      " [0.50955284]\n",
      " [0.45010132]\n",
      " [0.40226656]\n",
      " [0.37392932]\n",
      " [0.3539104 ]\n",
      " [0.34493133]\n",
      " [0.3466064 ]], shape=(8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "[mu, sigma] = ppo.actor_new(bs)\n",
    "print(mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[8, 1], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dist = tfp.distributions.Normal(mu,sigma)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[0.6112193 ],\n",
       "       [0.3208804 ],\n",
       "       [0.18997525],\n",
       "       [0.9526669 ],\n",
       "       [0.9697659 ],\n",
       "       [1.0217344 ],\n",
       "       [1.1285518 ],\n",
       "       [1.1496111 ]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.prob(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_in_choose = env.reset()\n",
    "s_in_choose = np.expand_dims(s_in_choose, axis=0)\n",
    "mu_choose,sigma_choose = ppo.actor_new(s_in_choose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[1, 1], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dist_choose = tfp.distributions.Normal(mu_choose, sigma_choose)\n",
    "print(dist_choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dist_choose.sample(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.61060979,  0.79193162, -0.06393755]),\n",
       " -0.8798268224680682,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
