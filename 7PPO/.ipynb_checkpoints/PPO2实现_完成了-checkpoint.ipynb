{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为啥训练到一定次数，ratio会变成nan？\n",
    "# 为什么pi_prob(a)是(32,1)\n",
    "# 而我的pi_prob(a)却是(32,32)\n",
    "# 我没有理解源码在建立actor网络的时候是怎么建立的，因为不需要构造模型，所以它出来pi不是32个state对应一个策略\n",
    "\n",
    "# 我知道问题出在哪了，因为之前的tfp和tensorflow是一体的，可以构造输出就是tfp的分布的模型\n",
    "# 而现在分开了，tfp的分布不属于一个op，所以没有办法放到模型里\n",
    "\n",
    "# 为什么mu，sigma我们俩的程序都是(32,1),但是莫凡的只输出了1个pi，我却输出了32个。\n",
    "# 也就是说，莫凡是输入了32个s，产生了32个mu，32个sigma，但是只产生了1个pi\n",
    "# 而我产生了32个mu，32个sigma，但是产生了32个pi，正因为如此，之后给了32个a，每个pi都产生了prob，所以prob形状是(32,32)，ratio自然也是(32,32),但是ratio要乘(32,1)的adv，所以出错了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_MAX = 300\n",
    "EP_LEN = 300\n",
    "GAMMA = 0.9\n",
    "A_LR = 0.0001\n",
    "C_LR = 0.0002\n",
    "BATCH = 32\n",
    "A_UPDATE_STEPS = 10\n",
    "C_UPDATE_STEPS = 10\n",
    "S_DIM, A_DIM = 3, 1   #举杆子的游戏就是这么个维度\n",
    "METHOD = [\n",
    "    dict(name='kl_pen', kl_target=0.01, lam=0.5),  #更新时候控制old和new参数近似的第一种方法KL\n",
    "    dict(name='clip', epsilon=0.2)                 #更新时的第二种方法CLIP\n",
    "][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'clip', 'epsilon': 0.2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO():\n",
    "    def __init__(self):\n",
    "        self.build_actor()  #创建actor,只创建一个actor，用的时候先后顺序用\n",
    "        self.build_critic() #创建critic\n",
    "\n",
    "    \n",
    "    def build_actor(self):\n",
    "        '''建立网络的结构，actor'''\n",
    "        # actor_new---------------------------------------------\n",
    "        s = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1 = tf.keras.layers.Dense(100, activation='relu',name='l1')(s)\n",
    "        mu = tf.keras.layers.Dense(A_DIM, activation='tanh',name='mu')(l1)\n",
    "        sigma = tf.keras.layers.Dense(A_DIM, activation='softplus',name='sigma')(l1)\n",
    "        \n",
    "        self.actor_new = tf.keras.Model(inputs=s, outputs=[mu,sigma])\n",
    "        self.a_optimizer = tf.keras.optimizers.Adam(A_LR)\n",
    "        \n",
    "        # actor_old-------------------------------------------------\n",
    "        s_1 = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1_1 = tf.keras.layers.Dense(100, activation='relu',name='l1')(s_1)\n",
    "        mu_1 = tf.keras.layers.Dense(A_DIM, activation='tanh',name='mu')(l1_1)\n",
    "        sigma_1 = tf.keras.layers.Dense(A_DIM, activation='softplus',name='sigma')(l1_1)\n",
    "        \n",
    "        self.actor_old = tf.keras.Model(inputs=s_1, outputs=[mu_1,sigma_1])\n",
    "    \n",
    "    def build_critic(self): \n",
    "        '''建立网络的结构，critic'''\n",
    "        # critic\n",
    "        s_c = tf.keras.layers.Input(shape=(S_DIM,))\n",
    "        l1_c = tf.keras.layers.Dense(100, activation='relu')(s_c)\n",
    "        v = tf.keras.layers.Dense(1)(l1_c)\n",
    "        \n",
    "        self.critic = tf.keras.Model(inputs=s_c, outputs=v)\n",
    "        self.c_optimizer = tf.keras.optimizers.Adam(C_LR)\n",
    "        \n",
    "    def update_new_old_actor(self):\n",
    "        '''更新老actor参数'''\n",
    "        #使用set_weights和get_weights的方法对每层的权重进行复制转移\n",
    "        #--------------------actor的两个网络的迁移--------------------------------\n",
    "        self.actor_old.set_weights(self.actor_new.get_weights())\n",
    "        \n",
    "    def learn(self, s, a, r):\n",
    "        '''学习，输入的是batch的s，会产生batch个normdist，对于batch的a，会产生batch*batch的proba'''      \n",
    "        # 旧网络产生的策略,不需要训练\n",
    "        [mu1, sigma1] = self.actor_old(s, training=False)\n",
    "        mu1 *= 2 #为了使-1,1到-2,2内部\n",
    "        \n",
    "        #不要squeeze，直接生成dis\n",
    "        pi_old = tfp.distributions.Normal(mu1, sigma1)  # pi_old是old网络的策略,一共有1个形状为[32,1]\n",
    "        \n",
    "        #每次学习更新一下新旧网络，\n",
    "        self.update_new_old_actor()\n",
    "        \n",
    "        #训练\n",
    "        with tf.GradientTape(persistent=True) as a_tap, tf.GradientTape(persistent=True) as c_tap:\n",
    "            # 新网络产生的策略\n",
    "            # 注意，网络产生的值一定要放在Gradient下面，不然没有梯度\n",
    "            [mu, sigma] = self.actor_new(s)\n",
    "            mu *= 2\n",
    "            \n",
    "            #不要squeeze\n",
    "            pi = tfp.distributions.Normal(mu, sigma)  # pi是现在的策略，[32,1]\n",
    "                    \n",
    "            #计算loss\n",
    "            v = self.critic(s) #计算s的价值\n",
    "            adv = r - v        #计算增益,形状是(32,1)\n",
    "\n",
    "            \n",
    "#             ratio = tf.exp(pi.log_prob(a) - pi_old.log_prob(a))\n",
    "            ratio = pi.prob(a) / pi_old.prob(a)    #ratio的shape应该是(32,1)!!!!!  ,这回肯定是了！\n",
    "#             print('ratio',ratio.shape)\n",
    "            \n",
    "            surr = ratio * adv\n",
    "            \n",
    "            # a的loss计算-------------------------------------------------------------------------------------------------\n",
    "            # a_loss的算法因为两种方法而不同\n",
    "            if METHOD['name'] == 'kl_pen':   # kl方法\n",
    "                lamda = METHOD['lam']\n",
    "                kl = tfp.distributions.kl_divergence(pi_old, pi)  #计算两个策略之间的KL散度\n",
    "                kl_mean = tf.reduce_mean(kl)\n",
    "                a_loss = -(tf.reduce_mean(surr - lamda * kl))\n",
    "                \n",
    "            else:                            # clip方法\n",
    "                a_loss = - tf.reduce_mean(tf.minimum(\n",
    "                    surr,\n",
    "                    tf.clip_by_value(ratio, 1.-METHOD['epsilon'], 1.+METHOD['epsilon'])*adv))\n",
    "                \n",
    "                \n",
    "            # c的loss计算--------------------------------------------------------------------------------------------------\n",
    "            c_loss = tf.reduce_mean(tf.square(adv))\n",
    "                    \n",
    "        # 更新actor----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        if METHOD['name'] == 'kl_pen':    #kl方法对应着kl的更新方式\n",
    "            for _ in range(A_UPDATE_STEPS): #给actor更新10次 ,grads在一个循环里面只能调用一次，所以，不能这么写，除非加上persistent\n",
    "                grads_a = a_tap.gradient(a_loss, self.actor_new.trainable_variables)\n",
    "                self.a_optimizer.apply_gradients(zip(grads_a, self.actor_new.trainable_variables))\n",
    "                # 设置内部终止条件\n",
    "                kl_now = kl_mean\n",
    "                if kl_now >4 * METHOD['kl_target']:\n",
    "                    break\n",
    "            if kl_now < METHOD['kl_target']/1.5:\n",
    "                METHOD['lam'] /= 2\n",
    "            elif kl_now > METHOD['kl_target']*1.5:\n",
    "                METHOD['lam'] *= 2\n",
    "            METHOD['lam'] = np.clip(METHOD['lam'], 1e-4, 10)\n",
    "        \n",
    "        else:                            #clip方法对应clip更新方式\n",
    "            for _ in range(A_UPDATE_STEPS): # 就是简单地用clip方式计算的loss给a更新10次\n",
    "                grads_a = a_tap.gradient(a_loss, self.actor_new.trainable_variables)\n",
    "                self.a_optimizer.apply_gradients(zip(grads_a, self.actor_new.trainable_variables))\n",
    "                \n",
    "        # 更新critic------------------------------------------------------------------------------------------------------------\n",
    "        for _ in range(C_UPDATE_STEPS):\n",
    "            grads_c = c_tap.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(grads_c, self.critic.trainable_variables)) \n",
    "        \n",
    "    def choose_action(self, s):\n",
    "        '''choose_action的时候就进来了一个s，所以只会产生一个normdist，也只会sample出来一个a'''\n",
    "        s = np.expand_dims(s, axis=0)\n",
    "        [mu, sigma] = self.actor_new(s, training=False)\n",
    "#         mu = tf.squeeze(mu*2)\n",
    "#         sigma = tf.squeeze(sigma)\n",
    "        mu *= 2\n",
    "        # 不要squeeze，这回就对了，输出形状是[1,1]只取第一维，得到[xx],对应着step！\n",
    "        #创建一个正态分布\n",
    "        normal_dist = tfp.distributions.Normal(mu, sigma)\n",
    "        act_choosed = tf.clip_by_value(normal_dist.sample(1)[0][0], -2,2)  \n",
    "        act_choosed = act_choosed.numpy()\n",
    "        return act_choosed\n",
    "    \n",
    "    def get_v(self, s):\n",
    "        if s.ndim < 2:\n",
    "            s = np.expand_dims(s, axis=0)\n",
    "        v = self.critic(s)\n",
    "        return v[0][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "all_ep_r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 0 |ep_r: -2233 \n",
      "EP: 1 |ep_r: -1935 \n",
      "EP: 2 |ep_r: -2548 \n",
      "EP: 3 |ep_r: -2150 \n",
      "EP: 4 |ep_r: -2348 \n",
      "EP: 5 |ep_r: -2462 \n",
      "EP: 6 |ep_r: -2078 \n",
      "EP: 7 |ep_r: -1891 \n",
      "EP: 8 |ep_r: -1644 \n",
      "EP: 9 |ep_r: -2189 \n",
      "EP: 10 |ep_r: -2459 \n",
      "EP: 11 |ep_r: -2176 \n",
      "EP: 12 |ep_r: -2170 \n",
      "EP: 13 |ep_r: -2217 \n",
      "EP: 14 |ep_r: -2337 \n",
      "EP: 15 |ep_r: -2157 \n",
      "EP: 16 |ep_r: -2165 \n",
      "EP: 17 |ep_r: -1896 \n",
      "EP: 18 |ep_r: -2024 \n",
      "EP: 19 |ep_r: -2002 \n",
      "EP: 20 |ep_r: -2575 \n",
      "EP: 21 |ep_r: -2140 \n",
      "EP: 22 |ep_r: -2439 \n",
      "EP: 23 |ep_r: -2044 \n",
      "EP: 24 |ep_r: -1762 \n",
      "EP: 25 |ep_r: -2617 \n",
      "EP: 26 |ep_r: -2227 \n",
      "EP: 27 |ep_r: -1916 \n",
      "EP: 28 |ep_r: -1651 \n",
      "EP: 29 |ep_r: -2258 \n",
      "EP: 30 |ep_r: -1657 \n",
      "EP: 31 |ep_r: -1767 \n",
      "EP: 32 |ep_r: -2061 \n",
      "EP: 33 |ep_r: -1965 \n",
      "EP: 34 |ep_r: -1987 \n",
      "EP: 35 |ep_r: -1679 \n",
      "EP: 36 |ep_r: -1837 \n",
      "EP: 37 |ep_r: -1774 \n",
      "EP: 38 |ep_r: -1943 \n",
      "EP: 39 |ep_r: -2355 \n",
      "EP: 40 |ep_r: -1798 \n",
      "EP: 41 |ep_r: -1827 \n",
      "EP: 42 |ep_r: -1991 \n",
      "EP: 43 |ep_r: -1781 \n",
      "EP: 44 |ep_r: -1666 \n",
      "EP: 45 |ep_r: -1715 \n",
      "EP: 46 |ep_r: -1442 \n",
      "EP: 47 |ep_r: -1941 \n",
      "EP: 48 |ep_r: -1628 \n",
      "EP: 49 |ep_r: -1733 \n",
      "EP: 50 |ep_r: -1477 \n",
      "EP: 51 |ep_r: -1678 \n",
      "EP: 52 |ep_r: -1619 \n",
      "EP: 53 |ep_r: -1485 \n",
      "EP: 54 |ep_r: -1663 \n",
      "EP: 55 |ep_r: -1576 \n",
      "EP: 56 |ep_r: -1637 \n",
      "EP: 57 |ep_r: -1542 \n",
      "EP: 58 |ep_r: -1428 \n",
      "EP: 59 |ep_r: -1250 \n",
      "EP: 60 |ep_r: -1978 \n",
      "EP: 61 |ep_r: -1659 \n",
      "EP: 62 |ep_r: -1659 \n",
      "EP: 63 |ep_r: -1582 \n",
      "EP: 64 |ep_r: -1279 \n",
      "EP: 65 |ep_r: -1796 \n",
      "EP: 66 |ep_r: -1127 \n",
      "EP: 67 |ep_r: -1536 \n",
      "EP: 68 |ep_r: -1544 \n",
      "EP: 69 |ep_r: -1318 \n",
      "EP: 70 |ep_r: -1541 \n",
      "EP: 71 |ep_r: -1745 \n",
      "EP: 72 |ep_r: -1123 \n",
      "EP: 73 |ep_r: -935 \n",
      "EP: 74 |ep_r: -1489 \n",
      "EP: 75 |ep_r: -1382 \n",
      "EP: 76 |ep_r: -890 \n",
      "EP: 77 |ep_r: -1297 \n",
      "EP: 78 |ep_r: -1139 \n",
      "EP: 79 |ep_r: -1432 \n",
      "EP: 80 |ep_r: -1336 \n",
      "EP: 81 |ep_r: -1417 \n",
      "EP: 82 |ep_r: -1151 \n",
      "EP: 83 |ep_r: -1412 \n",
      "EP: 84 |ep_r: -1491 \n",
      "EP: 85 |ep_r: -1319 \n",
      "EP: 86 |ep_r: -1453 \n",
      "EP: 87 |ep_r: -1142 \n",
      "EP: 88 |ep_r: -893 \n",
      "EP: 89 |ep_r: -1455 \n",
      "EP: 90 |ep_r: -1089 \n",
      "EP: 91 |ep_r: -1185 \n",
      "EP: 92 |ep_r: -1191 \n",
      "EP: 93 |ep_r: -910 \n",
      "EP: 94 |ep_r: -1024 \n",
      "EP: 95 |ep_r: -896 \n",
      "EP: 96 |ep_r: -1064 \n",
      "EP: 97 |ep_r: -907 \n",
      "EP: 98 |ep_r: -1167 \n",
      "EP: 99 |ep_r: -1552 \n",
      "EP: 100 |ep_r: -1025 \n",
      "EP: 101 |ep_r: -1087 \n",
      "EP: 102 |ep_r: -1307 \n",
      "EP: 103 |ep_r: -544 \n",
      "EP: 104 |ep_r: -911 \n",
      "EP: 105 |ep_r: -1046 \n",
      "EP: 106 |ep_r: -911 \n",
      "EP: 107 |ep_r: -1368 \n",
      "EP: 108 |ep_r: -1047 \n",
      "EP: 109 |ep_r: -1180 \n",
      "EP: 110 |ep_r: -1469 \n",
      "EP: 111 |ep_r: -908 \n",
      "EP: 112 |ep_r: -1220 \n",
      "EP: 113 |ep_r: -1163 \n",
      "EP: 114 |ep_r: -911 \n",
      "EP: 115 |ep_r: -784 \n",
      "EP: 116 |ep_r: -931 \n",
      "EP: 117 |ep_r: -1043 \n",
      "EP: 118 |ep_r: -648 \n",
      "EP: 119 |ep_r: -1589 \n",
      "EP: 120 |ep_r: -519 \n",
      "EP: 121 |ep_r: -1237 \n",
      "EP: 122 |ep_r: -1055 \n",
      "EP: 123 |ep_r: -914 \n",
      "EP: 124 |ep_r: -910 \n",
      "EP: 125 |ep_r: -788 \n",
      "EP: 126 |ep_r: -1389 \n",
      "EP: 127 |ep_r: -979 \n",
      "EP: 128 |ep_r: -791 \n",
      "EP: 129 |ep_r: -1044 \n",
      "EP: 130 |ep_r: -669 \n",
      "EP: 131 |ep_r: -1167 \n",
      "EP: 132 |ep_r: -526 \n",
      "EP: 133 |ep_r: -915 \n",
      "EP: 134 |ep_r: -1183 \n",
      "EP: 135 |ep_r: -898 \n",
      "EP: 136 |ep_r: -800 \n",
      "EP: 137 |ep_r: -1061 \n",
      "EP: 138 |ep_r: -1487 \n",
      "EP: 139 |ep_r: -133 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in range(EP_MAX):\n",
    "    s = env.reset()\n",
    "    buffer_s, buffer_a, buffer_r = [],[],[]\n",
    "    ep_r = 0\n",
    "    \n",
    "    for t in range(EP_LEN):\n",
    "        env.render()\n",
    "        a = ppo.choose_action(s)\n",
    "        s_, r, done, info = env.step(a)\n",
    "        buffer_s.append(s)\n",
    "        buffer_a.append(a)\n",
    "        buffer_r.append((r+8)/8)\n",
    "        s = s_\n",
    "        ep_r += r\n",
    "        \n",
    "        if (t+1)%BATCH==0 or t==EP_LEN-1:\n",
    "            v_s_ = ppo.get_v(s_)\n",
    "            discounted_r = []\n",
    "            for r in buffer_r[::-1]:\n",
    "                v_s_ = r + GAMMA * v_s_\n",
    "                discounted_r.append(v_s_)\n",
    "            discounted_r.reverse()\n",
    "            \n",
    "            bs, ba, br = np.vstack(buffer_s), np.vstack(buffer_a), np.expand_dims(np.array(discounted_r), axis=1)\n",
    "            \n",
    "            #清空三个buffer\n",
    "            buffer_s, buffer_a, buffer_r = [], [], []\n",
    "            \n",
    "            #学习\n",
    "            ppo.learn(bs, ba, br)\n",
    "            \n",
    "    # 用来显示奖励值\n",
    "    if ep == 0: all_ep_r.append(ep_r)\n",
    "    else: all_ep_r.append(all_ep_r[-1]*0.9 + ep_r*0.1)\n",
    "    \n",
    "    print('EP: %i'%ep,\n",
    "          '|ep_r: %i'%ep_r,\n",
    "          (\"|Lam: %.4f\" % METHOD['lam']) if METHOD['name'] == 'kl_pen' else '',\n",
    "          )\n",
    "    \n",
    "    if ep_r > -300:\n",
    "        break\n",
    "# 画图\n",
    "plt.plot(np.arange(len(all_ep_r)), all_ep_r)\n",
    "plt.xlabel('Episode');plt.ylabel('Moving averaged episode reward');plt.show()\n",
    "ppo.actor_new.save_weights('pp02_actor_weights.h5')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_test = PPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_test.actor_new.load_weights('pp02_actor_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5ba1fa0cd23d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEP_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppo_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0ms_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4edf6733b490>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m#创建一个正态分布\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mnormal_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mact_choosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mact_choosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact_choosed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mact_choosed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10315\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10316\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10317\u001b[1;33m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[0;32m  10318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10319\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(EP_MAX):\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(EP_LEN):\n",
    "        env.render()\n",
    "        a = ppo_test.choose_action(s)\n",
    "        s_, r, done, info = env.step(a)\n",
    "        s = s_\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何提取出全部的权重并且对权重进行运算，再赋值\n",
    "# 也就是软更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=(1,))\n",
    "x = tf.keras.layers.Dense(5)(i)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=i, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.get_weights()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = [w1*0.1 for w1 in w]\n",
    "print(w_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w1+w2 for w1,w2 in zip(w,w_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在建立网络的时候直接产生pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distnorm = tfp.distributions.Normal(0,1)\n",
    "dsitnorm2 = tfp.distributions.Normal([0,1],[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32)\n",
      "tfp.distributions.Normal(\"Normal\", batch_shape=[], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dsitnorm2)\n",
    "print(distnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16165093]\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "buffer_s, buffer_a, buffer_r = [],[],[]\n",
    "a = ppo.choose_action(s)\n",
    "print(a)\n",
    "for t in range(8):\n",
    "    ep_r = 0\n",
    "    a = ppo.choose_action(s)\n",
    "    s_, r, done, info = env.step(a)\n",
    "    buffer_s.append(s)\n",
    "    buffer_a.append(a)\n",
    "    buffer_r.append((r+8)/8)\n",
    "    s = s_\n",
    "    ep_r += r\n",
    "bs, ba, br = np.vstack(buffer_s), np.vstack(buffer_a), np.vstack(buffer_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05042878,  0.99872766,  0.66738899],\n",
       "       [-0.01850657,  0.99982874,  1.37915609],\n",
       "       [-0.12991862,  0.99152466,  2.23558554],\n",
       "       [-0.2813611 ,  0.95960196,  3.09850634],\n",
       "       [-0.45734555,  0.88928907,  3.79591537],\n",
       "       [-0.6434293 ,  0.76550554,  4.47923348],\n",
       "       [-0.81341724,  0.58168066,  5.02066649],\n",
       "       [-0.9401022 ,  0.34089274,  5.4585398 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24852428],\n",
       "       [ 0.7103859 ],\n",
       "       [ 0.79518205],\n",
       "       [-0.14861628],\n",
       "       [ 0.10900874],\n",
       "       [-0.21797436],\n",
       "       [ 0.01075213],\n",
       "       [-0.09659199]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70549313],\n",
       "       [ 0.66042514],\n",
       "       [ 0.57573741],\n",
       "       [ 0.44939201],\n",
       "       [ 0.29672194],\n",
       "       [ 0.1052202 ],\n",
       "       [-0.10939231],\n",
       "       [-0.34806021]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.05236873]\n",
      " [ 0.02980565]\n",
      " [ 0.00520472]\n",
      " [-0.03456562]\n",
      " [-0.05436929]\n",
      " [-0.06107465]\n",
      " [-0.06565797]\n",
      " [-0.079589  ]], shape=(8, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.5669595 ]\n",
      " [0.50955284]\n",
      " [0.45010132]\n",
      " [0.40226656]\n",
      " [0.37392932]\n",
      " [0.3539104 ]\n",
      " [0.34493133]\n",
      " [0.3466064 ]], shape=(8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "[mu, sigma] = ppo.actor_new(bs)\n",
    "print(mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[8, 1], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dist = tfp.distributions.Normal(mu,sigma)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[0.6112193 ],\n",
       "       [0.3208804 ],\n",
       "       [0.18997525],\n",
       "       [0.9526669 ],\n",
       "       [0.9697659 ],\n",
       "       [1.0217344 ],\n",
       "       [1.1285518 ],\n",
       "       [1.1496111 ]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.prob(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_in_choose = env.reset()\n",
    "s_in_choose = np.expand_dims(s_in_choose, axis=0)\n",
    "mu_choose,sigma_choose = ppo.actor_new(s_in_choose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[1, 1], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dist_choose = tfp.distributions.Normal(mu_choose, sigma_choose)\n",
    "print(dist_choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dist_choose.sample(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.61060979,  0.79193162, -0.06393755]),\n",
       " -0.8798268224680682,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
